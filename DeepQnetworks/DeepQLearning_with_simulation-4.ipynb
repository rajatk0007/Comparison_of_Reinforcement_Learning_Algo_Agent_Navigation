{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "oCnE56btJDrp"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers.advanced_activations import PReLU\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "2cAUBnVzhfco"
      },
      "outputs": [],
      "source": [
        "#create a user defined grid of size m*n\n",
        "def create_board(vertical,horizontal):\n",
        "    board = [[1 for column in range(vertical)] for  cell in range(horizontal)]\n",
        "    board = np.array(board)\n",
        "    return board"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJaA2jC-hwrv",
        "outputId": "d54634c9-8729-4ba2-b08c-75ce708d0870"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1, 1, 1, 1],\n",
              "       [1, 1, 1, 1, 1, 1],\n",
              "       [1, 1, 1, 1, 1, 1],\n",
              "       [1, 1, 1, 1, 1, 1],\n",
              "       [1, 1, 1, 1, 1, 1],\n",
              "       [1, 1, 1, 1, 1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "board = create_board(6,6)\n",
        "board"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "AFcVEDxOhzf-"
      },
      "outputs": [],
      "source": [
        "#define random points for obstacles except start and end points\n",
        "def intialize_obstacles(start,end):\n",
        "    obstacles = []\n",
        "    limit = int((board.shape[0]*board.shape[1])/4)\n",
        "    count = 0\n",
        "    while(count!=limit):\n",
        "        ran = np.random.randint((board.shape[0]*board.shape[1]))\n",
        "        if(ran!=start and ran!=end and ran not in obstacles):\n",
        "            obstacles.append(ran)\n",
        "            count+=1\n",
        "        else:\n",
        "            continue\n",
        "    return obstacles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "vZ71mFu4h2Wi"
      },
      "outputs": [],
      "source": [
        "#position obstacles\n",
        "def position_obstacles(board,obstacles):\n",
        "    horizontal = board.shape[0]\n",
        "    vertical = board.shape[1]\n",
        "    board = board.flatten()\n",
        "    for i in obstacles:\n",
        "        board[i] = 0\n",
        "    board = np.reshape(board,(vertical,horizontal))\n",
        "    return board"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "7_8JAgvhh5Al"
      },
      "outputs": [],
      "source": [
        "def multiplyList(l,col,row) :\n",
        "    res = col*(l[0])+l[1]\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "B1kAYvi5h7Pk"
      },
      "outputs": [],
      "source": [
        "start = [0,0]\n",
        "end = [5,5]\n",
        "\n",
        "vertical = 6\n",
        "horizontal = 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "y2x325sdmc-Y"
      },
      "outputs": [],
      "source": [
        "obstacles = intialize_obstacles(multiplyList(start,vertical,horizontal),multiplyList(end,vertical,horizontal))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ5I8O9cmfVo",
        "outputId": "a3d48761-1100-47a4-e589-9818683b3203"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1., 1., 1., 1., 1.],\n",
              "       [1., 1., 0., 0., 0., 1.],\n",
              "       [1., 1., 1., 1., 1., 0.],\n",
              "       [1., 0., 1., 1., 1., 1.],\n",
              "       [0., 1., 1., 1., 0., 0.],\n",
              "       [1., 1., 0., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "board_with_obstacles = position_obstacles(board,obstacles)\n",
        "board_with_obstacles = board_with_obstacles.astype(float)\n",
        "board_with_obstacles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-H0qXOaD0EFJ",
        "outputId": "122aaa8e-9cee-4f3d-ec2f-d6754baa09da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 6, 100.0)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "#reward matrix\n",
        "rewards = np.full((horizontal,vertical),-100.)\n",
        "rewards[end[0],end[1]]= 100\n",
        "for i in range(len(board_with_obstacles)):\n",
        "    for j in range(len(board_with_obstacles[0])):\n",
        "        # print(i,j)\n",
        "        if(board_with_obstacles[i][j]==1 and rewards[i][j]!=100):\n",
        "            rewards[i][j]=-1\n",
        "\n",
        "len(board_with_obstacles),len(board_with_obstacles[0]),rewards[end[0],end[1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6LcWLWr0SIB",
        "outputId": "22c0a131-dbea-499f-d647-681301f031eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  -1.,   -1.,   -1.,   -1.,   -1.,   -1.],\n",
              "       [  -1.,   -1., -100., -100., -100.,   -1.],\n",
              "       [  -1.,   -1.,   -1.,   -1.,   -1., -100.],\n",
              "       [  -1., -100.,   -1.,   -1.,   -1.,   -1.],\n",
              "       [-100.,   -1.,   -1.,   -1., -100., -100.],\n",
              "       [  -1.,   -1., -100.,   -1.,   -1.,  100.]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "rewards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "eemaR4E_KQjO"
      },
      "outputs": [],
      "source": [
        "class Grid_object(object):\n",
        "    def __init__(self,grid, start_pos=(start[0], start[1])):\n",
        "        self.grid = np.array(grid)\n",
        "        horizontal, vertical = self.grid.shape\n",
        "        self.target = (end[0], end[1])\n",
        "        self.paths = [(r, c) for r in range(horizontal)\n",
        "                      for c in range(vertical) if self.grid[r, c] == 1.0]\n",
        "        self.paths.remove(self.target)\n",
        "        self.Grid_reset(start_pos)\n",
        "\n",
        "    def Grid_reset(self, pos):\n",
        "        self.pos = pos\n",
        "        self.grid = np.copy(self.grid)\n",
        "        horizontal, vertical = self.grid.shape\n",
        "        row, col = pos\n",
        "        self.grid[row, col] = 0.5\n",
        "        self.state = (row, col, 'start')\n",
        "        self.min_reward = -0.5 * self.grid.size\n",
        "        self.total_reward = 0\n",
        "        self.visited = set()\n",
        "\n",
        "    def UpdateState(self, action):\n",
        "        horizontal, vertical = self.grid.shape\n",
        "        horizontal, vertical, nmode = pos_row, pos_col, mode = self.state\n",
        "        if self.grid[pos_row, pos_col] > 0.0:\n",
        "            self.visited.add((pos_row, pos_col))\n",
        "        valid_actions = self.valid_actions()\n",
        "        if not valid_actions:\n",
        "            nmode = 'blocked'\n",
        "        elif action in valid_actions:\n",
        "            nmode = 'valid'\n",
        "            if action == 0:\n",
        "                vertical -= 1\n",
        "            elif action == 1:\n",
        "                horizontal -= 1\n",
        "            if action == 2:\n",
        "                vertical += 1\n",
        "            elif action == 3:\n",
        "                horizontal += 1\n",
        "        else:\n",
        "            nmode = 'invalid'\n",
        "        self.state = (horizontal, vertical, nmode)\n",
        "\n",
        "    def get_reward(self):\n",
        "        pos_row, pos_col, mode = self.state\n",
        "        horizontal, vertical = self.grid.shape\n",
        "        if pos_row == end[0] and pos_col == end[1]:\n",
        "            return 1.0\n",
        "        if mode == 'blocked':\n",
        "            return self.min_reward - 1\n",
        "        if (pos_row, pos_col) in self.visited:\n",
        "            return -0.25\n",
        "        if mode == 'invalid':\n",
        "            return -0.75\n",
        "        if mode == 'valid':\n",
        "            return -0.04\n",
        "\n",
        "    def act(self, action):\n",
        "        self.UpdateState(action)\n",
        "        reward = self.get_reward()\n",
        "        self.total_reward += reward\n",
        "        status = self.game_status()\n",
        "        envstate = self.observe()\n",
        "        return envstate, reward, status\n",
        "\n",
        "    def observe(self):\n",
        "        canvas = self.draw_env()\n",
        "        envstate = canvas.reshape((1, -1))\n",
        "        return envstate\n",
        "\n",
        "    def draw_env(self):\n",
        "        canvas = np.copy(self.grid)\n",
        "        horizontal, vertical = self.grid.shape\n",
        "        for r in range(horizontal):\n",
        "            for c in range(vertical):\n",
        "                if canvas[r, c] > 0.0:\n",
        "                    canvas[r, c] = 1.0\n",
        "        row, col, valid = self.state\n",
        "        canvas[row, col] = 0.5\n",
        "        return canvas\n",
        "\n",
        "    def game_status(self):\n",
        "        if self.total_reward < self.min_reward:\n",
        "            return 'lose'\n",
        "        pos_row, pos_col, mode = self.state\n",
        "        horizontal, vertical = self.grid.shape\n",
        "        if pos_row == horizontal - 1 and pos_col == vertical - 1:\n",
        "            return 'win'\n",
        "        return 'not_over'\n",
        "\n",
        "    def valid_actions(self, cell=None):\n",
        "        if cell is None:\n",
        "            row, col, mode = self.state\n",
        "        else:\n",
        "            row, col = cell\n",
        "        actions = [0, 1, 2, 3]\n",
        "        horizontal, vertical = self.grid.shape\n",
        "        if row == 0:\n",
        "            actions.remove(1)\n",
        "        elif row == horizontal - 1:\n",
        "            actions.remove(3)\n",
        "        if col == 0:\n",
        "            actions.remove(0)\n",
        "        elif col == vertical - 1:\n",
        "            actions.remove(2)\n",
        "        if row > 0 and self.grid[row - 1, col] == 0.0:\n",
        "            actions.remove(1)\n",
        "        if row < horizontal - 1 and self.grid[row + 1, col] == 0.0:\n",
        "            actions.remove(3)\n",
        "        if col > 0 and self.grid[row, col - 1] == 0:\n",
        "            actions.remove(0)\n",
        "        if col < vertical - 1 and self.grid[row, col + 1] == 0.0:\n",
        "            actions.remove(2)\n",
        "        return actions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "If177xSUKQsP"
      },
      "outputs": [],
      "source": [
        "\n",
        "def solve_grid(model, grid_object, pos, show_maze=False):\n",
        "    action_lst = []\n",
        "    grid_object.Grid_reset(pos)\n",
        "    envstate = grid_object.observe()\n",
        "    while True:\n",
        "        prev_envstate = envstate\n",
        "        q = model.predict(prev_envstate)\n",
        "        action = np.argmax(q[0])\n",
        "        action_lst.append(action)\n",
        "        # print(action_lst)\n",
        "        envstate, reward, game_status = grid_object.act(action)\n",
        "        if game_status == 'win':\n",
        "            return True,action_lst\n",
        "        elif game_status == 'lose':\n",
        "            return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "KO6Li8MvKjfe"
      },
      "outputs": [],
      "source": [
        "def completion_check(model, grid_object):\n",
        "    for cell in grid_object.paths:\n",
        "        if not grid_object.valid_actions(cell):\n",
        "            return False\n",
        "        if not solve_grid(model, grid_object, cell):\n",
        "            return False\n",
        "    return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "M43lAoIdKjiT"
      },
      "outputs": [],
      "source": [
        "class Experience(object):\n",
        "\n",
        "    def __init__(self, model, max_memory=100, discount=0.95):\n",
        "        self.model = model\n",
        "        self.max_memory = max_memory\n",
        "        self.discount = discount\n",
        "        self.memory = list()\n",
        "        self.num_actions = model.output_shape[-1]\n",
        "\n",
        "    def save_memory(self, episode):\n",
        "        self.memory.append(episode)\n",
        "        if len(self.memory) > self.max_memory:\n",
        "            del self.memory[0]\n",
        "\n",
        "    def predict(self, envstate):\n",
        "        return self.model.predict(envstate)[0]\n",
        "\n",
        "    def get_data(self, data_size=10):\n",
        "        env_size = self.memory[0][0].shape[1]\n",
        "        mem_size = len(self.memory)\n",
        "        data_size = min(mem_size, data_size)\n",
        "        inputs = np.zeros((data_size, env_size))\n",
        "        targets = np.zeros((data_size, self.num_actions))\n",
        "        for i, j in enumerate(np.random.choice(range(mem_size), data_size,\n",
        "                                               replace=False)):\n",
        "            envstate, action, reward, envstate_next, game_over = self.memory[j]\n",
        "            inputs[i] = envstate\n",
        "            targets[i] = self.predict(envstate)\n",
        "            Q_sa = np.max(self.predict(envstate_next))\n",
        "            if game_over:\n",
        "                targets[i, action] = reward\n",
        "            else:\n",
        "                targets[i, action] = reward + self.discount * Q_sa\n",
        "        return inputs, targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "smJYkzD1KjlC"
      },
      "outputs": [],
      "source": [
        "def qtrain(model, grid, epsilon=0.1, **opt):\n",
        "    n_epoch = opt.get('n_epoch', 1000)\n",
        "    max_memory = opt.get('max_memory', 1000)\n",
        "    data_size = opt.get('data_size', 50)\n",
        "    weights_file = opt.get('weights_file', \"model.h5\")\n",
        "    name = opt.get('name', 'model')\n",
        "    start_time = datetime.datetime.now()\n",
        "    if weights_file:\n",
        "        try:\n",
        "            print(\"loading weights from file: %s\" % (weights_file,))\n",
        "            model.load_weights(weights_file)\n",
        "        except ValueError:\n",
        "            print(\"Incompatible model - starting from new model.\")\n",
        "            pass\n",
        "        except OSError:\n",
        "            print(\"Model does not exist - starting from new model.\")\n",
        "            pass\n",
        "    h5file = name + \".h5\"\n",
        "    json_file = name + \".json\"\n",
        "    grid_object = Grid_object(grid)\n",
        "    experience = Experience(model, max_memory=max_memory)\n",
        "    win_history = []\n",
        "    hsize = grid_object.grid.size // 2\n",
        "    win_rate = 0.0\n",
        "    for epoch in range(n_epoch):\n",
        "        loss = 0.0\n",
        "        pos = random.choice(grid_object.paths)\n",
        "        grid_object.Grid_reset(pos)\n",
        "        game_over = False\n",
        "        envstate = grid_object.observe()\n",
        "        n_episodes = 0\n",
        "        while not game_over:\n",
        "            valid_actions = grid_object.valid_actions()\n",
        "            if not valid_actions:\n",
        "                break\n",
        "            prev_envstate = envstate\n",
        "            if np.random.rand() < epsilon:\n",
        "                action = random.choice(valid_actions)\n",
        "            else:\n",
        "                action = np.argmax(experience.predict(prev_envstate))\n",
        "            envstate, reward, game_status = grid_object.act(action)\n",
        "            if game_status == 'win':\n",
        "                win_history.append(1)\n",
        "                game_over = True\n",
        "            elif game_status == 'lose':\n",
        "                win_history.append(0)\n",
        "                game_over = True\n",
        "            else:\n",
        "                game_over = False\n",
        "            episode = [prev_envstate, action, reward, envstate, game_over]\n",
        "            experience.save_memory(episode)\n",
        "            n_episodes += 1\n",
        "            inputs, targets = experience.get_data(data_size=data_size)\n",
        "            model.fit(inputs, targets, epochs=8, batch_size=16, verbose=0)\n",
        "            loss = model.evaluate(inputs, targets, verbose=0)\n",
        "        model.save_weights(h5file, overwrite=True)\n",
        "        with open(json_file, \"w\") as outfile:\n",
        "            json.dump(model.to_json(), outfile)\n",
        "        if len(win_history) > hsize:\n",
        "            win_rate = sum(win_history[-hsize:]) / hsize\n",
        "        dt = datetime.datetime.now() - start_time\n",
        "        t = format_time(dt.total_seconds())\n",
        "        template = \"Epoch: {:03d}/{:d} | Loss: {:.4f} | Episodes: {:d} | Win count: {:d} | Win rate: {:.3f} | Time: {}\"\n",
        "        print(template.format(epoch, n_epoch - 1, loss,\n",
        "                              n_episodes, sum(win_history), win_rate, t))\n",
        "        if win_rate > 0.9:\n",
        "            epsilon = 0.05\n",
        "        if win_rate==1:\n",
        "          break\n",
        "        if sum(win_history[-hsize:]) == hsize and completion_check(model,\n",
        "                                                                   grid_object):\n",
        "            print(\"Reached 100%% win rate at epoch: %d\" % (epoch,))\n",
        "            break\n",
        "    model.save_weights(h5file, overwrite=True)\n",
        "    with open(json_file, \"w\") as outfile:\n",
        "        json.dump(model.to_json(), outfile)\n",
        "    dt = datetime.datetime.now() - start_time\n",
        "    seconds = dt.total_seconds()\n",
        "    t = format_time(seconds)\n",
        "    print('files: %s, %s' % (h5file, json_file))\n",
        "    print(\"n_epoch: %d, max_mem: %d, data: %d, time: %s\" %\n",
        "          (epoch, max_memory, data_size, t))\n",
        "    return seconds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Qp172GgRKjnr"
      },
      "outputs": [],
      "source": [
        "def format_time(seconds):\n",
        "    if seconds < 400:\n",
        "        s = float(seconds)\n",
        "        return \"%.1f seconds\" % (s,)\n",
        "    elif seconds < 4000:\n",
        "        m = seconds / 60.0\n",
        "        return \"%.2f minutes\" % (m,)\n",
        "    else:\n",
        "        h = seconds / 3600.0\n",
        "        return \"%.2f hours\" % (h,)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "dZqlsg8tKjqR"
      },
      "outputs": [],
      "source": [
        "def deep_q_model(grid):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(grid.size, input_shape=(grid.size,)))\n",
        "    model.add(PReLU())\n",
        "    model.add(Dense(64))\n",
        "    model.add(PReLU())\n",
        "    model.add(Dense(16))\n",
        "    model.add(PReLU())\n",
        "    model.add(Dense(4))\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "SQtcfKi3vW46"
      },
      "outputs": [],
      "source": [
        "grid = board_with_obstacles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUZnWQVoKsVS",
        "outputId": "35be82e3-1aa3-4a4c-dcc8-e18667173f34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading weights from file: model.h5\n",
            "Model does not exist - starting from new model.\n",
            "Epoch: 000/999 | Loss: 0.0177 | Episodes: 82 | Win count: 0 | Win rate: 0.000 | Time: 218.4 seconds\n",
            "Epoch: 001/999 | Loss: 0.0073 | Episodes: 81 | Win count: 0 | Win rate: 0.000 | Time: 8.61 minutes\n",
            "Epoch: 002/999 | Loss: 0.0040 | Episodes: 82 | Win count: 0 | Win rate: 0.000 | Time: 13.65 minutes\n",
            "Epoch: 003/999 | Loss: 0.0029 | Episodes: 83 | Win count: 0 | Win rate: 0.000 | Time: 18.71 minutes\n",
            "Epoch: 004/999 | Loss: 0.0018 | Episodes: 82 | Win count: 0 | Win rate: 0.000 | Time: 23.69 minutes\n",
            "Epoch: 005/999 | Loss: 0.0155 | Episodes: 78 | Win count: 0 | Win rate: 0.000 | Time: 28.44 minutes\n",
            "Epoch: 006/999 | Loss: 0.0251 | Episodes: 80 | Win count: 0 | Win rate: 0.000 | Time: 33.31 minutes\n",
            "Epoch: 007/999 | Loss: 0.0316 | Episodes: 78 | Win count: 0 | Win rate: 0.000 | Time: 38.06 minutes\n",
            "Epoch: 008/999 | Loss: 0.0025 | Episodes: 5 | Win count: 1 | Win rate: 0.000 | Time: 38.37 minutes\n",
            "Epoch: 009/999 | Loss: 0.0250 | Episodes: 77 | Win count: 1 | Win rate: 0.000 | Time: 43.05 minutes\n",
            "Epoch: 010/999 | Loss: 0.0404 | Episodes: 80 | Win count: 1 | Win rate: 0.000 | Time: 47.95 minutes\n",
            "Epoch: 011/999 | Loss: 0.0050 | Episodes: 84 | Win count: 1 | Win rate: 0.000 | Time: 53.08 minutes\n",
            "Epoch: 012/999 | Loss: 0.0347 | Episodes: 85 | Win count: 1 | Win rate: 0.000 | Time: 58.25 minutes\n",
            "Epoch: 013/999 | Loss: 0.0023 | Episodes: 3 | Win count: 2 | Win rate: 0.000 | Time: 58.44 minutes\n",
            "Epoch: 014/999 | Loss: 0.0037 | Episodes: 86 | Win count: 2 | Win rate: 0.000 | Time: 63.69 minutes\n",
            "Epoch: 015/999 | Loss: 0.0029 | Episodes: 83 | Win count: 2 | Win rate: 0.000 | Time: 1.15 hours\n",
            "Epoch: 016/999 | Loss: 0.0029 | Episodes: 82 | Win count: 3 | Win rate: 0.000 | Time: 1.23 hours\n",
            "Epoch: 017/999 | Loss: 0.0098 | Episodes: 50 | Win count: 4 | Win rate: 0.000 | Time: 1.28 hours\n",
            "Epoch: 018/999 | Loss: 0.0071 | Episodes: 13 | Win count: 5 | Win rate: 0.278 | Time: 1.29 hours\n",
            "Epoch: 019/999 | Loss: 0.0235 | Episodes: 5 | Win count: 6 | Win rate: 0.333 | Time: 1.30 hours\n",
            "Epoch: 020/999 | Loss: 0.0145 | Episodes: 6 | Win count: 7 | Win rate: 0.389 | Time: 1.30 hours\n",
            "Epoch: 021/999 | Loss: 0.0217 | Episodes: 32 | Win count: 8 | Win rate: 0.444 | Time: 1.34 hours\n",
            "Epoch: 022/999 | Loss: 0.0205 | Episodes: 5 | Win count: 9 | Win rate: 0.500 | Time: 1.34 hours\n",
            "Epoch: 023/999 | Loss: 0.0135 | Episodes: 4 | Win count: 10 | Win rate: 0.556 | Time: 1.35 hours\n",
            "Epoch: 024/999 | Loss: 0.0118 | Episodes: 11 | Win count: 11 | Win rate: 0.611 | Time: 1.36 hours\n",
            "Epoch: 025/999 | Loss: 0.0040 | Episodes: 67 | Win count: 12 | Win rate: 0.667 | Time: 1.43 hours\n",
            "Epoch: 026/999 | Loss: 0.0045 | Episodes: 4 | Win count: 13 | Win rate: 0.667 | Time: 1.43 hours\n",
            "Epoch: 027/999 | Loss: 0.0052 | Episodes: 4 | Win count: 14 | Win rate: 0.722 | Time: 1.43 hours\n",
            "Epoch: 028/999 | Loss: 0.0036 | Episodes: 12 | Win count: 15 | Win rate: 0.778 | Time: 1.45 hours\n",
            "Epoch: 029/999 | Loss: 0.0038 | Episodes: 10 | Win count: 16 | Win rate: 0.833 | Time: 1.46 hours\n",
            "Epoch: 030/999 | Loss: 0.0034 | Episodes: 9 | Win count: 17 | Win rate: 0.889 | Time: 1.46 hours\n",
            "Epoch: 031/999 | Loss: 0.0015 | Episodes: 4 | Win count: 18 | Win rate: 0.889 | Time: 1.47 hours\n",
            "Epoch: 032/999 | Loss: 0.0015 | Episodes: 5 | Win count: 19 | Win rate: 0.944 | Time: 1.47 hours\n",
            "Epoch: 033/999 | Loss: 0.0028 | Episodes: 8 | Win count: 20 | Win rate: 1.000 | Time: 1.48 hours\n",
            "files: model.h5, model.json\n",
            "n_epoch: 33, max_mem: 1000, data: 50, time: 1.48 hours\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5336.138208"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "model = deep_q_model(grid)\n",
        "qtrain(model, grid)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_,action_lst = solve_grid(model, Grid_object(grid), (start[0], start[1]), show_maze=True)"
      ],
      "metadata": {
        "id": "iB2PfBdtCLL7"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "NETBjlidV7ly",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c590940-67ed-47bb-df98-cf646ba3a551"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 3, 3, 2, 3, 3, 2, 3, 2, 2]\n"
          ]
        }
      ],
      "source": [
        "print(action_lst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "S79bbV50r2Jq"
      },
      "outputs": [],
      "source": [
        "def make_path(start,action_lst):\n",
        "  path = []\n",
        "  current_cell = start\n",
        "  current_cell_new = start\n",
        "  print(current_cell)\n",
        "  for i in range(len(action_lst)):\n",
        "    current_cell = current_cell_new\n",
        "    if(action_lst[i]==0):\n",
        "      current_cell_new = [current_cell[0],current_cell[1]-1]\n",
        "      print(current_cell_new)\n",
        "      path.append(current_cell_new)\n",
        "    elif(action_lst[i]==1):\n",
        "      current_cell_new = [current_cell[0]-1,current_cell[1]]\n",
        "      print(current_cell_new)\n",
        "      path.append(current_cell_new)\n",
        "    elif(action_lst[i]==2):\n",
        "      current_cell_new = [current_cell[0],current_cell[1]+1]\n",
        "      print(current_cell_new)\n",
        "      path.append(current_cell_new)\n",
        "    else:\n",
        "      current_cell_new = [current_cell[0]+1,current_cell[1]]\n",
        "      print(current_cell_new)\n",
        "      path.append(current_cell_new)\n",
        "  return path\n",
        "\n",
        "\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "LJQmS38MuuHp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0546887a-b03e-4427-c6c1-0ac966c2f89c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0]\n",
            "[0, 1]\n",
            "[1, 1]\n",
            "[2, 1]\n",
            "[2, 2]\n",
            "[3, 2]\n",
            "[4, 2]\n",
            "[4, 3]\n",
            "[5, 3]\n",
            "[5, 4]\n",
            "[5, 5]\n"
          ]
        }
      ],
      "source": [
        "list1 = make_path(start,action_lst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "rewpayNBu0Z_"
      },
      "outputs": [],
      "source": [
        "list1.insert(0,start)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "BXkeorrxzIPr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2c1fc90-a7ae-4293-f6e3-9702a79281a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 0],\n",
              " [0, 1],\n",
              " [1, 1],\n",
              " [2, 1],\n",
              " [2, 2],\n",
              " [3, 2],\n",
              " [4, 2],\n",
              " [4, 3],\n",
              " [5, 3],\n",
              " [5, 4],\n",
              " [5, 5]]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "list1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "bddYeN6fzodS"
      },
      "outputs": [],
      "source": [
        "action_direction = dict()\n",
        "for i in range(len(list1)-1):\n",
        "  if(list1[i][0] - list1[i+1][0] == -1):\n",
        "    action_direction[(list1[i][0],list1[i][1])] = \"LEFT\"\n",
        "  elif(list1[i][0] - list1[i+1][0] == 1):\n",
        "    action_direction[(list1[i][0],list1[i][1])] = \"RIGHT\"\n",
        "  elif(list1[i][1] - list1[i+1][1] == -1):\n",
        "    action_direction[(list1[i][0],list1[i][1])] = \"UP\"\n",
        "  elif(list1[i][1] - list1[i+1][1] == 1):\n",
        "    action_direction[(list1[i][0],list1[i][1])] = \"DOWN\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "YZKWXkBOzsjI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3d063fd-9d0b-4725-db46-cc737e07a41a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{(0, 0): 'UP',\n",
              " (0, 1): 'LEFT',\n",
              " (1, 1): 'LEFT',\n",
              " (2, 1): 'UP',\n",
              " (2, 2): 'LEFT',\n",
              " (3, 2): 'LEFT',\n",
              " (4, 2): 'UP',\n",
              " (4, 3): 'LEFT',\n",
              " (5, 3): 'UP',\n",
              " (5, 4): 'UP'}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "action_direction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "3jKXIEkizuQu"
      },
      "outputs": [],
      "source": [
        "direction_map = {\n",
        "    'UP'   : ( 0, 1),\n",
        "    'DOWN' : ( 0,-1),\n",
        "    'RIGHT': ( 1, 0),\n",
        "    'LEFT' : (-1, 0)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "MmTHH-HzzwZK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "85912346-af92-4991-a174-c1d538c2f367"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD8CAYAAABekO4JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAASQklEQVR4nO3de5CddX3H8fc3m/uFS8htl3D1ggoq6lapoUWi3He1U0uEFv+wzsRa7ejYGa/Tjv5hHZ2OI1P/Ma1UqlaaGUEpIprhIqUTLrsQrgFECBBsCRADJNYEyLd/PBs3wG72hDznPL89+37NnMk5zzk5+fyyez7729/zPOdEZiJJKte0pgNIkvbNopakwlnUklQ4i1qSCmdRS1LhLGpJKlxLRR0RZ0bEfRHxQER8tt2hJEmjYqLjqCOiB7gfOA3YDNwCnJ+Z97Q/niSplRn124EHMvPBzNwFXAK8r72xJEl7TG/hMYcDj+51ezPwjpc+KCJWA6urW/PeBq+rIZ4kTRXDT2bm4rHuaaWoW5KZa4A1ABH9mauG63rqYsTaapkoV0XDSdrD8U1ujm/yqsYWD493fytLH48BR+x1e/nINklSB7RS1LcAr4mIYyJiJnAecHl7Y0mS9phw6SMzn4+IjwM/A3qAizLz7rYnkyQBLa5RZ+aVwJVtziJJGoNnJkpS4SxqSSqcRS1JhbOoJalwFrUkFc6ilqTCWdSSVDiLWpIKZ1FLUuFqe/e8Ov3HI3Dn0zDYB3+wEKZ135tlSVLLipxRn74M/ukBOOlq6L0c/vJmuGwzbH+u6WSS1HlFzqgv3gSHzIBnnoMtO+FfN1WXWdPg1CXVTHugF46c13BQSeqAImfUv3gCHvnty7fv3A1X/S987FY45kr462HYurPz+SSpk4qcUZ++FDZsg007Xrx9/nQ4Y1k1oz5rGSyZ3Uw+SeqkIov63CPg03dU14+eB4O9MNAHpyyGWT3NZpOkTiuyqK/bAp9/fTVzPv4gCI/6kDSFFVnUf3bExI/pVi/srn6b+Nir4UO3wAPb4atvgpnTIBM+cGTTCSV1WpFFPZX1TIPN/wev/Sn0BOzaDX81DDueh1ve03Q6SU0o8qiPqW6wD17IqqShKune2fDWQ5vNJakZFnWBzlr28rMxB/o8Q1OaqizqAh02C1Yc9uJtg33NZJHUPIu6UAN7FfPsHnj3kuaySGqWRV2ovWfQ714Cc93tK01ZFnWhXrcAXjW/uu6yhzS1WdSFiqjOyITqDagkTV0WdcEG+6pD8g6f23QSSU2yqAt28iK4wDMRpSlvwqKOiIsiYktE3NWJQBo1s6c6lVzS1NbKjPo7wJltzqFxzPTdAqUpb8Kizszrga0dyCJJGkNk5sQPijgauCIzT2jpSaM/YejAkknSlBLDmdk/1j217UyMiNURMRQRQ/BEXU8rSVNebee7ZeYaYA1UM+pc1X3vIBRrq98+unFsMDq+eXTn+Hbg+CazPePrxtffntfeeDw8T5IK18rheT8A1gPHRcTmiPhw+2NJkvaYcOkjM8/vRBBJ0thc+pCkwlnUklQ4i1qSCmdRS1LhLGpJKpxFLUmFs6glqXAWtSQVzqKWpMJZ1JJUOItakgpnUUtS4SxqSSqcRS1JhbOoJalwFrUkFc6iLswLu+EHj8Dzu+FTG+C89XDN4/DwDrhuS9PpJDWhtg+3VT16psFFD8Hf3QVP7YRtz8HGZ2Djs3DFyU2nk9QEZ9QFGuyFX22vShrgjqdh1jQ4ZXGzuSQ1w6Iu0EDfy7edvhRm9XQ+i6TmWdQFOnY+vOGgF28bHKO8JU0NFnWh9i7mAM7ubSyKpIZZ1IXau6hPOgyWzG4ui6RmWdSFOmkhHDazuu6yhzS1WdSF6pk2utwx4LKHNKVZ1AUb7IOj5sIJBzedRFKTPOGlYGcsgxufgoimk0hqkjPqgh00Az73+qZTSGrahEUdEUdExLURcU9E3B0Rn+hEMFUWzWo6gaSmtbL08Tzwt5l5a0QsAIYjYl1m3tPmbJIkIDJz//5CxI+Bb2bmuvEf058wdKDZJGkKieHM7B/rnv1ao46Io4G3ADeNcd/qiBiKiCF44pWklCSNoeWjPiJiPvBD4JOZ+cxL78/MNcCa6rH9mau671CFWFv99tGNYwPHN9lNlfHNo/vGt4N9r2y0NKOOiBlUJf39zLy0hlySpBa1ctRHAN8GNmbm19sfSZK0t1Zm1CuADwIrI2LDyOXsNueSJI2YcI06M2+ALlwUkqRJwjMTJalwFrUkFc6ilqTCWdSSVDiLWpIKZ1FLUuEsakkqnEUtSYWzqBtw229g5wtNp5A0WVjUDbh2Cyz6Mbz/v+E7D8ETv2s6kaSSWdQNeM/S6s9LH4MP3QJLL4d3Xg1f2Qh3PQ37+VkOkrqcn0LegHP+C7Y/P3o7gfVPVZfP3wlHz4OBXhjsg1OXwAx/nEpTmhVQoEUzYfGs6jLdt8OSpjxn1A24YSWc8LPRWfWcHjhtaTWDPrsX+uY0m09SWSzqBnz3YTh4BlxwVLXEsXIJzPErIWkc1kMD/vxI+MLrIabgssbWnbCb6gfVPz9YbTt3OcydDtt2weFzG40nFcmibsCx85tO0JzZPXDUT+AvjoQLf1lt27ANfvRYtSQk6eXcmaiOmjsd3rFwtKShmlkfOhNeu6C5XFLJLGp13GDfGNt6O59DmiwsanXcwBilPFZ5S6pY1Oq4w+fCWw8dvX3IDFixqLk8UuksajVi71n1Wb0w3e9EaVy+PNSIvZc6XPaQ9s2iViPeeij0zoaegDOXNZ1GKpvHUasR0wIG+uCXz1aH5kkan0WtxgyOFLWkfbOo1Zh3L4ETDmo6hVS+CdeoI2J2RNwcEbdHxN0R8aVOBFP3mzsdjpnCp9NLrWplRr0TWJmZ2yNiBnBDRPw0M29sczZJEhC5H5/7FBFzgRuAj2bmTeM/rj9hqIZ4kjRVxHBm9o91T0uH50VET0RsALYA68Yq6YhYHRFDETEETxxYXknS7+3vjPoQ4DLgbzLzrvEf15+5ariGeGWJtdX/1Ty6842kd1CNL1d15/j2fP0c3+TUzeOrxnaAM+o9MnMbcC1wZg3ZJEktaOWoj8UjM2kiYg5wGnBvu4NJkiqtHPXRC1wcET1Uxb42M69obyxJ0h4TFnVm3gG8pQNZJElj8E2ZJKlwFrUkFc6ilqTCWdSSVDiLWpIKZ1FLUuEsakkqnEUtSYWzqCWpcBa1JBXOopakwlnUklQ4i1qSCmdRS1LhLGpJKlwrHxwg1WbnCzBzGiRw99PVtlfPhznTq/tm9TQaTyqSM2p11NPPwTuvgUs3w5t+Xl0u3gRnXQ+3bWs6nVQmZ9TqqCWzIYBz149u++itsGQWvH1hY7GkojmjVscN9r182zm9MC06n0WaDCxqddxA7xjbxihvSRWLWh13wsFw1NzR2zOnwelLm8sjlc6iVsdFvHj549QlMH9Gc3mk0lnUasTeRT04xlKIpFEWtRpxymKYP3LMkevT0r55eJ4aMaunWpf+5XY4al7TaaSyWdRqzGBfVdSS9s2iVmPO7oVNO5pOIZWv5aKOiB5gCHgsMwfaF0lTxZLZ1UXSvu3PzsRPABvbFUSSNLbIzIkfFLEcuBj4MvCpiWbUEf1ZTb4lSa2J4czsH+ueVmfU3wA+Dewe95+IWB0RQxExBE+8gpCSpLFMuEYdEQPAlswcjoh3jfe4zFwDrKn+Tn/Oo/veYWcH1W8fuar7xgYQax3fZLZnfN342oPR1183jm/P2MbTyox6BfDeiNgEXAKsjIjvHXg0SVIrJizqzPxcZi7PzKOB84BrMvOCtieTJAGeQi5JxduvE14y8zrgurYkkSSNyRm1JBXOopakwlnUklQ4i1qSCmdRS1LhLGpJKpxFLUmFs6glqXAWtSQVzqJWrXYnfGQILrwfHvTzEKVaWNSq1bSAdyyET26AV10Jx18Fn7kdbngCXhj33cwl7YsfbqtaPb0LfvTr0dv3PFNdvnYfHDaz+kDbwT44fSkcPLO5nNJk4oxatdq5G/7z12Pf99Qu+O7DsGo9vPHncMkj0MInwUlTnjNq1WpOD3zkWPjWgy+/782HwODIjLp/YbVMImliFrVqtWAGHLeguj5rGqxcAgN9MNALR85rNps0WVnUqtXuhCd3wWUr4D1LYP6MphNJk59FrVpNC/jyG5tO0ZxrHodbf1Mt85y7HgK48wz46r3wxePhsFlNJ9RkZFFLNXrLoXD69TA9qh2rUB2m+KaDLWm9ch71IdXo0JnwR4tGSxpg1+5qB6r0SlnUUs3GKmWLWgfCopZq9tJSXj4HTjykmSzqDha1VLPXLBg9RBGqwxPDY8Z1ACxqqQ0Gese+Lr0SFrXUBnuWP+b0VCf9SAfCw/OkNlixaPQIkDm+ynSA/BaS2mD6NDhrGZzqbFo1sKilNnlvH/zx4qZTqBu0VNQRsQl4FngBeD4z+9sZSuoG719ezaylA7U/M+pTM/PJtiWRuowlrbr4rSRJhYts4SM2IuIh4DdAAt/KzDX7fnx/wlA9CSVpSojh8ZaVW136ODkzH4uIJcC6iLg3M69/0T8RsRpYXd068gDCSpL21tKM+kV/IeKLwPbM/MfxH9OfuWr4AKOVJ9ZW/1e5qjvPB94zvnl05/h2MDW+fl0/vi78nM3qLQbGn1FPuEYdEfMiYsGe68DpwF11hpQkja+VpY+lwGVRVf504N8z86q2ppIk/d6ERZ2ZDwJv7kAWSdIYPDxPkgpnUUtS4SxqSSqcRS1JhbOoJalwFrUkFc6ilqTCWdSSVDiLWpIKZ1FL+2HrTrjwfvjV9qaTtMcd2+A7D8GW3zWdRHuzqKX9sHAWrHscXn0lvOEq+MztcMMT8PzuppPV43UL4O/vhmWXwx9eDf9wD9y5rTvfsW4y8cNtpf2waQcsnV1d3/hMdfnafbBwJpzdC4N9cMZSOHhmszlfqdu2VWX96G/hxqeqyxfugqPmVmMb6IN3LYZZPU0nnVqcUUv7YeMzcNFDL9++dRd872H4wHpY9GM47RfVTHuyWfd4dXmph38L33wAzry+Gt/567t3+adEzqil/XDQDDhuAdz37Mvvm9MDpy2tZp7n9ELvnM7nO1C9s+GIudWM+qUO2/u3hmXV/4U6w6KW9sOKRfCnh8NX7q1uHz5nZEmgF1YugTmT/BX14WNh7aOjRf2Gg6rxDfbBSQuhx9/BGzHJv62kztq6E27aCl86viqvEw/Z8zFK3WFoK+wGLjyxWo8+dn7TiQQWtbRfDp0JV7+r6RTt87ZDYd0pTafQS/mLjLQfumn2PJZuH99kZVFLUuEsakkqnEUtSYWzqCWpcBa1JBXOopakwlnUklQ4i1qSCmdRS1LhLGpJKpxFLUmFs6glqXCRbfgwtIj+hKHan1eSulcMZ2b/mPe0p6jjWeC+2p+4DIuAJ5sO0UaOb3JzfJPXUZm5eKw72vV+1PeN95NhsouIoW4dGzi+yc7xdSfXqCWpcBa1JBWuXUW9pk3PW4JuHhs4vsnO8XWhtuxMlCTVx6UPSSqcRS1Jhau1qCPizIi4LyIeiIjP1vncTYuIiyJiS0Tc1XSWdoiIIyLi2oi4JyLujohPNJ2pThExOyJujojbR8b3paYz1S0ieiLitoi4ouksdYuITRFxZ0RsiIgpdzZdbWvUEdED3A+cBmwGbgHOz8x7avkHGhYRfwxsB/4tM09oOk/dIqIX6M3MWyNiATAM/EkXff0CmJeZ2yNiBnAD8InMvLHhaLWJiE8B/cBBmTnQdJ46RcQmoD8zu/Vkl32qc0b9duCBzHwwM3cBlwDvq/H5G5WZ1wNbm87RLpn5P5l568j1Z4GNwOHNpqpPVraP3JwxcumaPekRsRw4B/iXprOofnUW9eHAo3vd3kwXvdCnkog4GngLcFOzSeo1sjSwAdgCrMvMbhrfN4BPA7ubDtImCfw8IoYjYnXTYTrNnYl6kYiYD/wQ+GRmPtN0njpl5guZeSKwHHh7RHTFElZEDABbMnO46SxtdHJmvhU4C/jYyFLklFFnUT8GHLHX7eUj2zRJjKzd/hD4fmZe2nSedsnMbcC1wJlNZ6nJCuC9I+u4lwArI+J7zUaqV2Y+NvLnFuAyqqXWKaPOor4FeE1EHBMRM4HzgMtrfH610cjOtm8DGzPz603nqVtELI6IQ0auz6Ha6X1vs6nqkZmfy8zlmXk01evumsy8oOFYtYmIeSM7uImIecDpQFcefTWe2oo6M58HPg78jGpH1NrMvLuu529aRPwAWA8cFxGbI+LDTWeq2Qrgg1SzsQ0jl7ObDlWjXuDaiLiDalKxLjO77jC2LrUUuCEibgduBn6SmVc1nKmjPIVckgrnzkRJKpxFLUmFs6glqXAWtSQVzqKWpMJZ1JJUOItakgr3/znxP/StcSVmAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def arrow_position(location, arrow_direction):\n",
        "    if arrow_direction == 'UP':\n",
        "        correction = (.5, .3)\n",
        "    elif arrow_direction == 'DOWN':\n",
        "        correction = (.6, .3)\n",
        "    elif arrow_direction == 'RIGHT':\n",
        "        correction = (.4, .5)\n",
        "    elif arrow_direction == 'LEFT':\n",
        "        correction = (.6, .5)\n",
        "    return (location[0]+correction[0],\n",
        "            location[1]+correction[1])\n",
        "fig, ax = plt.subplots()\n",
        "plt.xlim(0,horizontal)\n",
        "plt.ylim(vertical,0)\n",
        "plt.pcolormesh(rewards,edgecolor='b',cmap=plt.cm.hot)\n",
        "# plt.grid(True)\n",
        "plt.xticks(np.arange(0, horizontal, 1.0))\n",
        "plt.yticks(np.arange(0, vertical, 1.0))\n",
        "\n",
        "locations = action_direction.keys()\n",
        "for location in locations:\n",
        "    arrow_direction = action_direction[location]\n",
        "    x_pos, y_pos = arrow_position(location, arrow_direction)\n",
        "    x_direct, y_direct = direction_map[arrow_direction]\n",
        "    ax.quiver(\n",
        "        y_pos,x_pos,\n",
        "        y_direct,x_direct,\n",
        "        scale=30)\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "DeepQLearning_with_simulation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
